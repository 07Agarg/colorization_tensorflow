{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COLORIZATION.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1H2UicwgifwFcFfM_I0w_K1NTZPyGojUW",
          "timestamp": 1522884011463
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "P5f_Ia6mJbSB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "1bbcee89-d7ec-4395-add1-d0b7f1d3a6d4"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmp30opz1l6/pubring.gpg' created\n",
            "gpg: /tmp/tmp30opz1l6/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CWMIbHZ0Jdfe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WVXNc_Sy-3m_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sclb9R13-6kV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "  os.chdir(\"drive/app\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S7lKJFwV_akQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f35fe531-fbb7-42b1-ee36-c754232b8619",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525734374716,
          "user_tz": -330,
          "elapsed": 2191,
          "user": {
            "displayName": "Ashima Garg",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106898311207793946100"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colorization_model.ipynb  outputs  test  TestColabNotebook.ipynb  train\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jO0vaTA1FONk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "866a12e6-6498-47e2-9654-387bb97530b2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525734392405,
          "user_tz": -330,
          "elapsed": 9598,
          "user": {
            "displayName": "Ashima Garg",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106898311207793946100"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import cv2\n",
        "#import os\n",
        "import re\n",
        "import sys\n",
        "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from scipy.misc import imsave \n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "zxq0AAjmFR0k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "NUM_EPOCHS = 500\n",
        "EVAL_FREQUENCY = 1\n",
        "#FLAGS = tf.app.flags.FLAGS\n",
        "\n",
        "batch_size = 70"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Onw2F2z-FT-L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "INITIAL_LEARNING_RATE = 0.001       # Initial learning rate.\n",
        "num = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mef-p2hFFW0G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#def data_type():\n",
        " # if FLAGS.use_fp16:\n",
        " #   return tf.float16\n",
        " # else:\n",
        " #   return tf.float32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I8-mefIDFYtk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def display_images(color_imgs):\n",
        "    global num\n",
        "    color_imgs_shape = np.shape(color_imgs)\n",
        "    print(\"color imgs shape shape \" + str(color_imgs_shape))\n",
        "    for i in range(color_imgs_shape[0]):\n",
        "       # print(\"i is \" + str(i))\n",
        "       \n",
        "       num += 1\n",
        "       imsave('outputs/generatedImg' + str(num) + '.jpg', color_imgs[i])\n",
        "       if num >= 70:\n",
        "          num = 0\n",
        "       #cv2.imshow('image',color_imgs[i])\n",
        "       #cv2.waitKey(0) \n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYJJwxyDFbSh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def read_img(filename):\n",
        "    print(\"filename \" + str(filename))\n",
        "    img = cv2.imread(filename)\n",
        "    height, width, channels = img.shape\n",
        "   # greyimg = cv2.cvtColor(cv2.resize(img, (224, 224)),cv2.COLOR_BGR2GRAY)\n",
        "    colorimg = cv2.cvtColor(cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE)),cv2.COLOR_BGR2LAB)\n",
        "    colorimg = colorimg.astype(np.float)/255.\n",
        "    #return greyimg, colorimg\n",
        "    return colorimg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vuMprHczFdub",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create(dirname):\n",
        "    filenames = os.listdir(dirname)\n",
        "    print(\"dirname \" + str(dirname))\n",
        "    x_img = []\n",
        "    y_img = []\n",
        "    for filename in filenames:\n",
        "        #grey, color = read_img(dirname+filename)\n",
        "        #grey_3 = np.atleast_3d(grey)\n",
        "        color = read_img(dirname + filename)\n",
        "        color_l = color[:,:,0]\n",
        "        color_l3 = np.atleast_3d(color_l)\n",
        "        color_ab = color[:,:,1:]\n",
        "        x_img.append(color_l3)\n",
        "        y_img.append(color_ab)\n",
        "        \n",
        "    x_img = np.asarray(x_img)\n",
        "    y_img = np.asarray(y_img)\n",
        "    return x_img, y_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eee1PaH5FiXF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_network(image):\n",
        "\t# low_level_conv1\n",
        "    with tf.variable_scope('low_level_conv1') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 1, 64], stddev=5e-2))\n",
        "        bias = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "        conv = tf.nn.conv2d(image, weight, [1, 2, 2, 1], padding=\"SAME\")\n",
        "        low_level_conv1 = tf.nn.relu(tf.nn.bias_add(conv, bias))\n",
        "#        _activation_summary(low_level_conv1)\n",
        "\n",
        "\t# low_level_conv2\n",
        "    with tf.variable_scope('low_level_conv2') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128],stddev=5e-2))\n",
        "        bias = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "        conv = tf.nn.conv2d(low_level_conv1, weight, [1, 1, 1, 1], padding=\"SAME\")\n",
        "        low_level_conv2 = tf.nn.relu(tf.nn.bias_add(conv, bias))\n",
        "#        _activation_summary(low_level_conv2)\n",
        "    \n",
        "\t# low_level_conv3\n",
        "    with tf.variable_scope('low_level_conv3') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=5e-2))\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "        conv = tf.nn.conv2d(low_level_conv2, weight, [1, 2, 2, 1], padding='SAME')\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        low_level_conv3 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(low_level_conv3)\n",
        "\n",
        "\t# low_level_conv4\n",
        "    with tf.variable_scope('low_level_conv4') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 256], stddev=5e-2))\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[256]))\n",
        "        conv = tf.nn.conv2d(low_level_conv3, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        low_level_conv4 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(low_level_conv4)    \n",
        "\n",
        "\t# low_level_conv5\n",
        "    with tf.variable_scope('low_level_conv5') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 256, 256], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(low_level_conv4, weight, [1, 2, 2, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.0, shape=[256]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        low_level_conv5 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(low_level_conv5)\n",
        "\n",
        "\t# low_level_conv6\n",
        "    with tf.variable_scope('low_level_conv6') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 256, 512], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(low_level_conv5, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        low_level_conv6 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(low_level_conv6)\n",
        "\n",
        "\t# mid_level_conv1\n",
        "    with tf.variable_scope('mid_level_conv1') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 512, 512],stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(low_level_conv6, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        mid_level_conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(mid_level_conv1)\n",
        "\n",
        "\t# mid_level_conv2\n",
        "    with tf.variable_scope('mid_level_conv2') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 512, 256], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(mid_level_conv1, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[256]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        mid_level_conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(mid_level_conv2)\n",
        "\n",
        "\t# global_level_conv1\n",
        "    with tf.variable_scope('global_level_conv1') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 512, 512], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(low_level_conv6, weight, [1, 2, 2, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        global_level_conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(global_level_conv1)\n",
        "\n",
        "\t# global_level_conv2\n",
        "    with tf.variable_scope('global_level_conv2') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 512, 512], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(global_level_conv1, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        global_level_conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(global_level_conv2)\n",
        "\n",
        "\t# global_level_conv3\n",
        "    with tf.variable_scope('global_level_conv3') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 512, 512], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(global_level_conv2, weight, [1, 2, 2, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        global_level_conv3 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(global_level_conv3)\n",
        "\n",
        "\t# global_level_conv4\n",
        "    with tf.variable_scope('global_level_conv4') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 512, 512], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(global_level_conv3, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        global_level_conv4 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(global_level_conv4)\n",
        "        global_level_conv4_shape = global_level_conv4.get_shape().as_list()\n",
        "        \n",
        "\t# global_level_FC1\n",
        "    with tf.variable_scope('global_level_FC1') as scope:\n",
        "        #flatten = tf.reshape(conv_5, [conv5_shape[0], conv5_shape[1]*conv5_shape[2]*conv5_shape[3]])\n",
        "        #print(\"global level conv4 shape \" + str(global_level_conv4_shape))\n",
        "        flatten = tf.contrib.layers.flatten(global_level_conv4)\n",
        "        #flatten = tf.reshape(global_level_conv4, [batch_size, global_level_conv4_shape[1] * global_level_conv4_shape[2] * global_level_conv4_shape[3]])\n",
        "        #print(\"reshape global level conv4 \" + str(flatten.get_shape()))\n",
        "        dim = flatten.get_shape()[1].value\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[dim, 1024], stddev=0.04))\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[1024]))\n",
        "        global_level_FC1 = tf.nn.relu(tf.matmul(flatten, weight) + biases, name=scope.name)\n",
        "#        _activation_summary(global_level_FC1)\n",
        "        print(\"global level FC1 \" + str(global_level_FC1.get_shape()))\n",
        "\t\n",
        "\t# global_level_FC2\n",
        "    with tf.variable_scope('global_level_FC2') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[1024, 512], stddev=0.04))\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "        global_level_FC2 = tf.nn.relu(tf.matmul(global_level_FC1, weight) + biases, name=scope.name)\n",
        "#        _activation_summary(global_level_FC2)\n",
        " #       print(\"global level FC2 \" + str(global_level_FC2.get_shape()))\n",
        "    \n",
        "\t# global_level_FC3\n",
        "    with tf.variable_scope('global_level_FC3') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[512, 256], stddev=0.04))\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[256]))\n",
        "        global_level_FC3 = tf.nn.relu(tf.matmul(global_level_FC2, weight) + biases, name=scope.name)\n",
        "#        _activation_summary(global_level_FC3)\n",
        "        print(\"global level FC3 \" + str(global_level_FC3.get_shape()))\n",
        "        \n",
        "\t# fusion_layer\n",
        "    with tf.variable_scope('fusion_layer') as scope:\n",
        "        \n",
        "        global_level_FC3_reshaped = tf.expand_dims(global_level_FC3, 1)\n",
        "        print(\"global_level_FC3_reshaped \" + str(global_level_FC3_reshaped.get_shape()))\n",
        "        \n",
        "        mid_level_conv2_shape = mid_level_conv2.get_shape().as_list()\n",
        "        mid_level_conv2_reshaped = tf.reshape(mid_level_conv2, [batch_size, mid_level_conv2_shape[1] * mid_level_conv2_shape[2], 256])\n",
        "        print(\"mid level conv2 shape reshaped \" + str(mid_level_conv2_reshaped.get_shape()))\n",
        "        mid_level_conv2_reshaped_shape = mid_level_conv2_reshaped.get_shape().as_list()\n",
        "       # global_level_FC3_tiled = tf.zeros_like(global_level_FC3_reshaped)\n",
        "        global_level_FC3_tiled = []\n",
        "        for i in range(global_level_FC3_reshaped.get_shape()[0]):\n",
        "           # print(\"in loop \" + str(global_level_FC3_reshaped[i].get_shape()))\n",
        "            global_temp = tf.tile(global_level_FC3_reshaped[i], [mid_level_conv2_reshaped_shape[1], 1])\n",
        "           # print(\"globaltemp \"  +str(global_temp.get_shape()))\n",
        "            global_level_FC3_tiled.append(global_temp)\n",
        "            #global_level_FC3_new[i] = tf.tile(global_level_FC3_reshaped[i], [mid_level_conv2_reshaped.get_shape()[1], mid_level_conv2_reshaped.get_shape()[2]])\n",
        "            #print(\"in loop \" + str(global_level_FC3_reshaped[i].get_shape())\n",
        "        global_level_FC3_tiled = tf.stack(global_level_FC3_tiled)\n",
        "        print(\"...........global_level_FC3_new \" + str(global_level_FC3_tiled.get_shape()))\n",
        "        \n",
        "        fusion_level = tf.concat([global_level_FC3_tiled, mid_level_conv2_reshaped], 2)\n",
        "        print(\"fusion level \" + str(fusion_level.get_shape()))\n",
        "        \n",
        "        '''\n",
        "        print(\"mid level conv2 shape \" + str(mid_level_conv2.get_shape()))\n",
        "        mid_level_conv2_shape = mid_level_conv2.get_shape().as_list()\n",
        "        mid_level_conv2_reshaped = tf.reshape(mid_level_conv2, [batch_size, mid_level_conv2_shape[1] * mid_level_conv2_shape[2], 256])\n",
        "        fusion_level = []\n",
        "        for j in range(mid_level_conv2_reshaped.shape[0]):\n",
        "            for i in range(mid_level_conv2_reshaped.shape[1]):\n",
        "                see_mid = mid_level_conv2_reshaped[j, i, :]\n",
        "                see_mid_shape = see_mid.get_shape().as_list()\n",
        "                see_mid = tf.reshape(see_mid, [1, see_mid_shape[0]])\n",
        "                global_level_FC3_shape = global_level_FC3[j, :].get_shape().as_list()\n",
        "                see_global = tf.reshape(global_level_FC3[j, :], [1, global_level_FC3_shape[0]])\n",
        "                fusion = tf.concat([see_mid, see_global], 1)\n",
        "                fusion_level.append(fusion)\n",
        "#        print(\"1 . mid level conv2 reshape \" + str(mid_level_conv2_reshaped.get_shape()))\n",
        "        #mid_level_conv2_reshaped = tf.unstack(mid_level_conv2_reshaped,axis=0)\t\n",
        "        #mp = tf.stack([mid_level_conv2_reshaped])\n",
        "                \n",
        "                #print(\"fusion \" + str(fusion.get_shape()))\n",
        "            \n",
        "        fusion_level = tf.stack(fusion_level, 1)\n",
        "        print(\"fusion level \" + str(fusion_level.get_shape()))\n",
        "        #fusion_level = [tf.concat([see_mid,global_level_FC3],0) for see_mid in mid_level_conv2_reshaped]\n",
        "        #fusion_level = tf.stack(fusion_level)\n",
        "        '''\n",
        "        fusion_level = tf.reshape(fusion_level,[batch_size, 28, 28, 512])\t\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[1, 1, 512, 256], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(fusion_level, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[256]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        fusion_layer = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(fusion_layer)\n",
        "\t\n",
        "\t# colorization_level_conv1\n",
        "    with tf.variable_scope('colorization_level_conv1') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 256, 128], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(fusion_layer, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        colorization_level_conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "        colorization_level_conv1_upsampled = tf.image.resize_images(colorization_level_conv1, [56, 56], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "#        _activation_summary(colorization_level_conv1_upsampled)\n",
        "\t\t\n",
        "\t# colorization_level_conv2\n",
        "    with tf.variable_scope('colorization_level_conv2') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 64], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(colorization_level_conv1_upsampled, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        colorization_level_conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(colorization_level_conv2)\n",
        "\n",
        "\t# colorization_level_conv3\n",
        "    with tf.variable_scope('colorization_level_conv3') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 64], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(colorization_level_conv2, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        colorization_level_conv3 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "        colorization_level_conv3_upsampled = tf.image.resize_images(colorization_level_conv3, [112, 112], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "#        _activation_summary(colorization_level_conv3_upsampled)\n",
        "                \n",
        "    # colorization_level_conv4\n",
        "    with tf.variable_scope('colorization_level_conv4') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 32], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(colorization_level_conv3_upsampled, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[32]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        colorization_level_conv4 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "#        _activation_summary(colorization_level_conv4)\n",
        "                \n",
        "   # output_layer\n",
        "    with tf.variable_scope('output_layer') as scope:\n",
        "        weight = tf.Variable(tf.truncated_normal(shape=[3, 3, 32, 2], stddev=5e-2))\n",
        "        conv = tf.nn.conv2d(colorization_level_conv4, weight, [1, 1, 1, 1], padding='SAME')\n",
        "        biases = tf.Variable(tf.constant(0.1, shape=[2]))\n",
        "        pre_activation = tf.nn.bias_add(conv, biases)\n",
        "        output_layer = tf.nn.sigmoid(pre_activation, name=scope.name)\n",
        "#        _activation_summary(output_layer)\n",
        "        print(\"output_layer \"  + str(output_layer.get_shape()))\n",
        "    return output_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9aU3C63eFlo4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def trainNetwork():\n",
        "    \n",
        "    #with tf.Graph().as_default():\n",
        "    #global_step = tf.train.get_or_create_global_step()\n",
        "    #path = os.path.dirname(os.path.realpath(__file__))\n",
        "    #path = \"drive/app\"\n",
        "    file = \"train/\"\n",
        "    dirname = file\n",
        "    x_img_train, y_img_train = create(dirname)\n",
        "    x_img_train_shape = x_img_train.shape\n",
        "    y_img_train_shape = y_img_train.shape\n",
        "    #print(\"y train type \" + str(type(y_img_train)))\n",
        "    #print(type(x_img_train))\n",
        "    #TRAIN SIZE\n",
        "    train_size = x_img_train_shape[0]\n",
        "    #print(\"train data complete\")\n",
        "    \n",
        "    X_input_train = tf.placeholder(dtype = tf.float32, shape = (batch_size, IMAGE_SIZE, IMAGE_SIZE, 1), name = \"input_tensor\")\n",
        "    Y_output_train = tf.placeholder(dtype = tf.float32, shape = (batch_size, IMAGE_SIZE, IMAGE_SIZE, 2), name = \"output_tensor\")\n",
        "    \n",
        "    # X_input_test = tf.placeholder(dtype = data_type(), shape = (FLAGS.batch_size_test, IMAGE_SIZE, IMAGE_SIZE, 1), name = \"input_tensor\")\n",
        "    #print(type(x_temp))\n",
        "\n",
        "    print(\"............y img train shape \" + str(y_img_train_shape))\n",
        "    '''\n",
        "      y_img_train_norm = []\n",
        "    print(\"y_temp shape \" + str(y_temp.shape))\n",
        "    print(\"y_temp ith shape \" + str(y_temp[0].shape))\n",
        "    print(\"1 type y_temp \" + str(type(y_temp)))\n",
        "    \n",
        "    y_temp_float = tf.cast(y_temp[0] , tf.float32) * (1. / 255)\n",
        "    print(\"2 type y_temp_float \" + str(type(y_temp_float)))\n",
        "    print(\"y_temp float shape \" +str(y_temp_float.shape))\n",
        "    for i in range(y_img_train_shape[0]):\n",
        "        #print\n",
        "        y_ = np.array(y_temp[i] , np.float32) * (1. / 255)\n",
        "        y_img_train_norm.append(y_)\n",
        "    \n",
        "    y_img_train_norm = np.array(y_img_train, np.float32) / 255.\n",
        "    \n",
        "    \n",
        "    #print(\"y_img_train_norm shape \" + str(np.shape(y_img_train_norm)))\n",
        "    #y_img_train_norm[i, :] = tf.cast(y_img_train[i, :] , tf.float32) * (1. / 255)\n",
        "    #y_img_train_norm = tf.map_fn(lambda image_raw: tf.cast(image_raw , tf.float32) * (1. / 255), y_img_train)\n",
        "    #print(\"y norm type \" + str(type(y_img_train_norm)))   \n",
        "    '''\n",
        "    print(\"x_img_train_shape \" + str(x_img_train_shape))\n",
        "    logits = create_network(X_input_train)\n",
        "    print(\"1............logits shape \" +str(logits.shape))\n",
        "    \n",
        "    print(\"logits type \" + str(type(logits)))\n",
        "    #logits_norm = []\n",
        "    '''\n",
        "    for i in range(logits.shape[0]):\n",
        "        logits_ = tf.cast(logits[i, :] , tf.float32) * (1. / 255)\n",
        "        logits_norm.append(logits_)\n",
        "    '''\n",
        "    #logits_norm = tf.map_fn(lambda image_raw : tf.cast(image_raw , tf.float32) * (1. / 255), logits)\n",
        "    #logits_norm = logits / 255.\n",
        "    #print(\"2............logits shape \" +str(logits.shape))\n",
        "    #print(\"3............logits norm shape \" +str(logits_norm.shape))\n",
        "    #logits_norm = tf.cast(logits , tf.float32) * (1. / 255)\n",
        "    #logits_norm = tf.image.convert_image_dtype(logits, tf.float32)\n",
        "    logits_train = tf.image.resize_images(logits, [224, 224], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    print(\"created\")\n",
        "    print(\"logits 2 shape \" + str(logits_train.get_shape()))\n",
        "#    color_output = tf.concat((x_temp, logits_train), axis = 3)\n",
        "    #print(\"logits size \" + str(logits.get_shape()))\n",
        "    #logits_norm = cv2.normalize(logits, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=-1)\n",
        "    #TypeError: src is not a numpy array, neither a scalar\n",
        "    #logits_2 = cv2.resize(logits_norm, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_CUBIC)\n",
        "   # x = cv2.resize(x_img[0], (224, 224, 1))\n",
        "   # x = tf.reshape(x_img[0], [IMAGE_SIZE, IMAGE_SIZE, 1])\n",
        "    #process test data\n",
        "    filetest = \"test/\"\n",
        "    testdirname = filetest\n",
        "#   x_img_test, y_img_test = create(testdirname)\n",
        "    #print(\"test data complete\")\n",
        "    #logits_test = create_network(X_input_test)\n",
        "  #  batch = tf.Variable(0, dtype=data_type())\n",
        "#   loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y_output_train, logits=logits_train))\n",
        "    loss = tf.reduce_mean(tf.square((Y_output_train) - (logits_train)))\n",
        "    #learning_rate = tf.train.exponential_decay(0.01, batch * FLAGS.batch_size, train_size, 0.95, staircase=True)\n",
        "    optimizer = tf.train.AdadeltaOptimizer(INITIAL_LEARNING_RATE, rho = 0.95, epsilon = 1e-08).minimize(loss)\n",
        "    #optimizer = tf.train.GradientDescentOptimizer(1e-4).minimize(loss)\n",
        "   # print(sess.run(loss, feed_dict = {X_input_train: x_img_train, Y_output_train: y_img_train})) \n",
        "    #sess.run(optimizer, feed_dict = {X_input_train: x_img_train, Y_output_train: y_img_train})    \n",
        "    start_time = time.time()    \n",
        "    with tf.Session() as sess:\n",
        "        print(\"session created\")\n",
        "        init = tf.global_variables_initializer()\n",
        "        sess.run(init)\n",
        "        for step in range(int(NUM_EPOCHS * train_size) // batch_size):\n",
        "          #offset = (step * batch_size) % (train_size - batch_size)\n",
        "          \n",
        "          #batch_data = x_temp[offset:(offset + batch_size)]\n",
        "          #batch_labels = y_img_train_norm[offset:(offset + batch_size)]\n",
        "          #print(\"y_img train_norm \" + str(y_img_train_norm.shape))\n",
        "          #print(\"batch data shape \" + str(batch_data.shape))\n",
        "          #print(\"batch labels shape \" + str(np.shape(batch_labels)))\n",
        "          #print(\"logits_train shape \" +str(logits_train.shape))\n",
        "          \n",
        "          feed_dict = {X_input_train: x_img_train, Y_output_train: y_img_train}\n",
        "          #print(\"x temp batch shape \" + str(batch_data.shape))\n",
        "           #print(\"color output \" + str(color_output.shape))\n",
        "          _, l, predictions = sess.run([optimizer, loss, logits_train], feed_dict=feed_dict)\n",
        "          color_output = tf.concat((x_img_train, logits_train), axis = 3)\n",
        "          color_imgs = sess.run(color_output, feed_dict = feed_dict)\n",
        "          if step % EVAL_FREQUENCY == 0:    \n",
        "              display_images(color_imgs)\n",
        "              elapsed_time = time.time() - start_time\n",
        "              start_time = time.time()\n",
        "              print('Step %d (epoch %.2f), %.1f ms' %(step, float(step) * batch_size / train_size, 1000 * elapsed_time / EVAL_FREQUENCY))\n",
        "              print('Minibatch loss: %.3f' % (l))\n",
        "              #print('Minibatch error: %.1f%%' % error_rate(predictions, batch_labels))\n",
        "              #print('Minibatch error: %.1f%%' % error_rate(predictions, batch_labels))\n",
        "              #print('Validation error: %.1f%%' % error_rate(\n",
        "              #eval_in_batches(validation_data, sess), validation_labels))\n",
        "              sys.stdout.flush()\n",
        "    # Finally print the result!\n",
        "    #test_error = error_rate(eval_in_batches(test_data, sess), test_labels)\n",
        "    ##print('Test error: %.1f%%' % test_error)\n",
        "    #if FLAGS.self_test:\n",
        "     # print('test_error', test_error)\n",
        "     # assert test_error == 0.0, 'expected 0.0 test_error, got %.2f' % (test_error,)\n",
        "\n",
        "    #color_output = []\n",
        "    #for i in range(FLAGS.batch_size):\n",
        "   \n",
        "    #print(\"optimizer \" + str(optimizer))\n",
        "    \n",
        "    #logits_test = create_network(X_input_test)\n",
        "    \n",
        "    #correct_prediction = tf.equal(tf.argmax(logits), tf.argmax(Y_output))\n",
        "    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "    #loss = loss(logits, labels)\n",
        "    # Build a Graph that trains the model with one batch of examples and\n",
        "    # updates the model parameters.\n",
        "    #train_op = build_model.train(loss, global_step)\n",
        "    #sess.run(train_op, feed_dict = {})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rpYMLEloFoIU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "68c09cac-0d57-4ea0-b7a4-556c62060b5e",
        "executionInfo": {
          "status": "error",
          "timestamp": 1525736759188,
          "user_tz": -330,
          "elapsed": 1038,
          "user": {
            "displayName": "Ashima Garg",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106898311207793946100"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    #sess = tf.InteractiveSession()\n",
        "    trainNetwork()\n",
        "    print(\"training completed\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d7725cc9fd07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#sess = tf.InteractiveSession()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training completed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainNetwork' is not defined"
          ]
        }
      ]
    }
  ]
}